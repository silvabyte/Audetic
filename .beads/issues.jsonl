{"id":"Audetic-2nl","title":"Easy local whisper inference \u0026 transcription server setup","description":"Make setting up a local whisper inference server and transcription management server super easy for end users.\n\n## Architecture\n- **inference-server-manager** (Bun/Elysia): API gateway that wraps whisper.cpp server with simple JSON API, handles context bleed by rotating whisper instances after N requests\n- **whisper-server** (C++): Actual inference, Vulkan-accelerated for AMD GPUs\n\n## Current State\n- inference-server-manager: DONE - ported to packages/inference-server-manager/ (commit 04cee1e)\n- whisper-server: IN PROGRESS - see epic Audetic-vuu\n\n## Related\n- Epic: Audetic-vuu (Port whisper-server to Audetic monorepo)\n- Subtask: Audetic-2nl.1 (superseded by Audetic-vuu)\n\n## Goal\nOpen source both components so users can run locally instead of using hosted service:\n```toml\n[transcription]\nprovider = \"audetic\"\nendpoint = \"http://localhost:8080/api/v1/transcriptions\"\n```","status":"open","priority":1,"issue_type":"feature","created_at":"2025-12-02T15:18:14.711747552-05:00","updated_at":"2025-12-19T16:49:47.77679907-05:00"}
{"id":"Audetic-2nl.1","title":"Extract transcription-manager from Arcata into new public repo","description":"Create new public repo (silvabyte/audetic-transcription-server or similar).\n\nTasks:\n- Create new GitHub repo with MIT license\n- Copy transcription-manager code from Arcata/apps/transcription-manager\n- Remove Arcata-specific dependencies/config\n- Add proper package.json with correct name/description\n- Add basic README with what this does\n- Set up CI (lint, test if any exist)","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-17T11:16:41.040713684-05:00","updated_at":"2025-12-17T11:16:41.040713684-05:00","dependencies":[{"issue_id":"Audetic-2nl.1","depends_on_id":"Audetic-2nl","type":"parent-child","created_at":"2025-12-17T11:16:41.041670262-05:00","created_by":"daemon"}]}
{"id":"Audetic-2nl.2","title":"Clean up transcription-manager code for open source","description":"Make the code presentable and configurable for public use.\n\nTasks:\n- Audit for any secrets/credentials (remove or env-var them)\n- Add proper configuration (env vars or config file) for:\n  - Port\n  - Whisper server path/command\n  - Request rotation threshold (N requests before restart)\n  - Model path\n- Add JSDoc/comments for key functions\n- Clean up any dead code or TODOs\n- Ensure error handling is solid","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-17T11:16:48.419304268-05:00","updated_at":"2025-12-17T11:16:48.419304268-05:00","dependencies":[{"issue_id":"Audetic-2nl.2","depends_on_id":"Audetic-2nl","type":"parent-child","created_at":"2025-12-17T11:16:48.420048984-05:00","created_by":"daemon"},{"issue_id":"Audetic-2nl.2","depends_on_id":"Audetic-2nl.1","type":"blocks","created_at":"2025-12-17T11:16:48.420916714-05:00","created_by":"daemon"}]}
{"id":"Audetic-2nl.3","title":"Consolidate whisper.cpp build scripts into transcription server repo","description":"Bring the hardware-specific build scripts from matsilva/whisper into the transcription server repo.\n\nTasks:\n- Copy build scripts (build.sh, build-macos-apple-silicon.sh, build-arch-linux.sh, quantize-model.sh)\n- Add install script that:\n  - Clones whisper.cpp (upstream or fork)\n  - Runs appropriate build script for detected platform\n  - Downloads recommended model\n- Document supported platforms (macOS Apple Silicon, Arch Linux, Ubuntu)\n- Add Windows/WSL guidance or script if feasible","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-17T11:16:56.348977714-05:00","updated_at":"2025-12-17T11:16:56.348977714-05:00","dependencies":[{"issue_id":"Audetic-2nl.3","depends_on_id":"Audetic-2nl","type":"parent-child","created_at":"2025-12-17T11:16:56.349909676-05:00","created_by":"daemon"},{"issue_id":"Audetic-2nl.3","depends_on_id":"Audetic-2nl.1","type":"blocks","created_at":"2025-12-17T11:16:56.3508949-05:00","created_by":"daemon"}]}
{"id":"Audetic-2nl.4","title":"Write comprehensive README and setup documentation","description":"Documentation for users to get running locally.\n\nREADME should cover:\n- What this is (API gateway for whisper.cpp with context bleed fix)\n- Quick start (one-liner if possible)\n- Prerequisites (Node.js version, build tools)\n- Installation steps:\n  1. Clone repo\n  2. Run install script (builds whisper.cpp for your hardware)\n  3. Download model\n  4. Start server\n- Configuration options (env vars)\n- API documentation (POST /api/v1/transcriptions)\n- Troubleshooting common issues\n- Performance tuning tips per platform","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-17T11:17:03.261099991-05:00","updated_at":"2025-12-17T11:17:03.261099991-05:00","dependencies":[{"issue_id":"Audetic-2nl.4","depends_on_id":"Audetic-2nl","type":"parent-child","created_at":"2025-12-17T11:17:03.261663302-05:00","created_by":"daemon"},{"issue_id":"Audetic-2nl.4","depends_on_id":"Audetic-2nl.2","type":"blocks","created_at":"2025-12-17T11:17:03.262432055-05:00","created_by":"daemon"},{"issue_id":"Audetic-2nl.4","depends_on_id":"Audetic-2nl.3","type":"blocks","created_at":"2025-12-17T11:17:03.26303903-05:00","created_by":"daemon"}]}
{"id":"Audetic-2nl.5","title":"Update Audetic docs for local transcription server","description":"Add documentation to Audetic (this repo) for using local server.\n\nTasks:\n- Add new doc page (docs/local-transcription-server.md or similar)\n- Explain when/why to use local vs hosted\n- Link to audetic-transcription-server repo\n- Show config example:\n  ```toml\n  [transcription]\n  provider = \"audetic\"\n  endpoint = \"http://localhost:8080/api/v1/transcriptions\"\n  ```\n- Update existing provider docs to mention local option","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-17T11:17:09.35690305-05:00","updated_at":"2025-12-17T11:17:09.35690305-05:00","dependencies":[{"issue_id":"Audetic-2nl.5","depends_on_id":"Audetic-2nl","type":"parent-child","created_at":"2025-12-17T11:17:09.357562365-05:00","created_by":"daemon"},{"issue_id":"Audetic-2nl.5","depends_on_id":"Audetic-2nl.4","type":"blocks","created_at":"2025-12-17T11:17:09.358324976-05:00","created_by":"daemon"}]}
{"id":"Audetic-2nl.6","title":"Add Ubuntu/Debian build script","description":"Currently have macOS Apple Silicon and Arch Linux. Add Ubuntu/Debian support.\n\nTasks:\n- Create build-ubuntu.sh (or build-debian.sh)\n- Handle apt dependencies (build-essential, cmake, etc.)\n- Detect CUDA if available, otherwise CPU-only\n- Test on Ubuntu 22.04 and 24.04\n- Add to platform detection in main build.sh","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-17T11:17:16.224942711-05:00","updated_at":"2025-12-17T11:17:16.224942711-05:00","dependencies":[{"issue_id":"Audetic-2nl.6","depends_on_id":"Audetic-2nl","type":"parent-child","created_at":"2025-12-17T11:17:16.225649307-05:00","created_by":"daemon"},{"issue_id":"Audetic-2nl.6","depends_on_id":"Audetic-2nl.3","type":"blocks","created_at":"2025-12-17T11:17:16.226649281-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz","title":"Port inference-server-manager to Audetic monorepo","description":"Port transcription-manager from Arcata monorepo to Audetic as inference-server-manager. This is a Bun-native HTTP service that manages WhisperServer worker pools for audio transcription. Powers voice.audetic.link API.\n\nKey decisions:\n- Rename package to inference-server-manager\n- Keep XDG config path as ~/.config/transcription_manager/ for backward compat\n- Strip unused deps (sharp, clipboardy, AI SDKs, WorkOS)\n- Make CORS configurable via CORS_ORIGIN env var\n- Simplify logger (remove identity context, default to info level)\n- New README tailored to Audetic","status":"closed","priority":0,"issue_type":"epic","created_at":"2025-12-19T15:20:43.013666185-05:00","updated_at":"2025-12-19T15:30:43.037013497-05:00","closed_at":"2025-12-19T15:30:43.037013497-05:00"}
{"id":"Audetic-8jz.1","title":"Update root package.json with catalog dependencies","description":"Add required dependencies to workspace catalog:\n- elysia: ^1.4.8\n- @elysiajs/openapi: ^1.4.11\n- pino: ^9.11.0\n- pino-pretty: ^13.1.1\n- pino-roll: ^3.1.0\n- json5: ^2.2.3\n- lodash.merge: ^4.6.2\n- xdg-basedir: ^5.1.0\n- @types/node: ^22.13.9\n\nAdd to dev catalog:\n- @types/lodash.merge: ^4.6.9\n\nFiles: package.json","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-19T15:21:01.030080933-05:00","updated_at":"2025-12-19T15:23:07.277294695-05:00","closed_at":"2025-12-19T15:23:07.277294695-05:00","dependencies":[{"issue_id":"Audetic-8jz.1","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:21:01.030629032-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.10","title":"Port src/config.ts with renamed types","description":"Port config.ts with modifications:\n- Rename TranscriptionManagerConfig -\u003e InferenceServerConfig\n- Rename WorkerConfig schema (keep as-is, just type rename)\n- Keep WhisperServer schema\n- Keep JSON5 config loading with XDG base directory\n- Keep lodash.merge for config merging\n\nFiles: packages/inference-server-manager/src/config.ts","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-19T15:21:31.952364989-05:00","updated_at":"2025-12-19T15:28:44.32981377-05:00","closed_at":"2025-12-19T15:28:44.32981377-05:00","dependencies":[{"issue_id":"Audetic-8jz.10","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:21:31.952720733-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.11","title":"Port src/workers/index.ts as-is","description":"Copy workers/index.ts from source without modifications. Contains:\n- Worker process spawning using Bun.spawn\n- Worker lifecycle management\n- Stdout/stderr streaming\n- Graceful shutdown (2s delay before kill)\n\nFiles: packages/inference-server-manager/src/workers/index.ts","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-19T15:21:33.794533504-05:00","updated_at":"2025-12-19T15:28:44.340195341-05:00","closed_at":"2025-12-19T15:28:44.340195341-05:00","dependencies":[{"issue_id":"Audetic-8jz.11","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:21:33.795067465-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.12","title":"Port src/manager/index.ts as-is","description":"Copy manager/index.ts from source without modifications. Contains:\n- Worker pool orchestration\n- Round-robin load balancing\n- Health checks (every 5s, 2s timeout, 3 failures triggers replacement)\n- Audit sweep (every 30s, checks process liveness)\n- Worker recycling after N requests (configurable)\n- Exponential backoff for failed spawns\n\nFiles: packages/inference-server-manager/src/manager/index.ts","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-19T15:21:36.576586079-05:00","updated_at":"2025-12-19T15:28:44.35127913-05:00","closed_at":"2025-12-19T15:28:44.35127913-05:00","dependencies":[{"issue_id":"Audetic-8jz.12","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:21:36.577122074-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.13","title":"Port src/routes/index.ts as-is","description":"Copy routes/index.ts from source without modifications. Contains API routes:\n- GET /health - Service health + worker pool status\n- POST /api/v1/transcriptions - Submit audio for transcription\n- GET /api/v1/providers - List available providers\n- GET /api/v1/status - Detailed worker pool status\n\nUses TypeBox schemas for request/response validation.\n\nFiles: packages/inference-server-manager/src/routes/index.ts","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-19T15:21:46.17066822-05:00","updated_at":"2025-12-19T15:28:44.370955234-05:00","closed_at":"2025-12-19T15:28:44.370955234-05:00","dependencies":[{"issue_id":"Audetic-8jz.13","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:21:46.171492306-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.14","title":"Port src/app.ts with configurable CORS","description":"Port app.ts with modifications:\n- Change hardcoded CORS origin 'http://localhost:5173' to use CORS_ORIGIN env var\n- Keep Elysia app factory pattern\n- Keep OpenAPI plugin\n- Keep route registration\n\nBefore:\n  set.headers['Access-Control-Allow-Origin'] = 'http://localhost:5173';\n\nAfter:\n  const allowedOrigin = Bun.env.CORS_ORIGIN ?? 'http://localhost:5173';\n  set.headers['Access-Control-Allow-Origin'] = allowedOrigin;\n\nFiles: packages/inference-server-manager/src/app.ts","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-19T15:21:49.503166446-05:00","updated_at":"2025-12-19T15:28:44.385750988-05:00","closed_at":"2025-12-19T15:28:44.385750988-05:00","dependencies":[{"issue_id":"Audetic-8jz.14","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:21:49.503679176-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.15","title":"Port src/index.ts entry point","description":"Copy index.ts from source. Entry point that:\n1. Initializes config\n2. Initializes observability\n3. Initializes manager (worker pool)\n4. Starts HTTP server\n\nMay need to update port env var name from TRANSCRIPTION_MANAGER_PORT to INFERENCE_SERVER_PORT.\n\nFiles: packages/inference-server-manager/src/index.ts","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-19T15:21:51.422829121-05:00","updated_at":"2025-12-19T15:28:44.396575893-05:00","closed_at":"2025-12-19T15:28:44.396575893-05:00","dependencies":[{"issue_id":"Audetic-8jz.15","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:21:51.423373532-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.16","title":"Create README.md tailored to Audetic","description":"Create new README.md for the package:\n- What it does (WhisperServer worker pool manager for voice.audetic.link)\n- Architecture overview\n- Environment variables (INFERENCE_SERVER_PORT, WHISPER_SERVER_CMD, WHISPER_SERVER_CWD, CORS_ORIGIN, LOG_LEVEL)\n- Config file location (~/.config/transcription_manager/settings.json5)\n- API endpoints documentation\n- How to run (bun run dev, bun run start)\n- Deployment notes\n\nFiles: packages/inference-server-manager/README.md","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-19T15:21:54.971708559-05:00","updated_at":"2025-12-19T15:29:28.695776527-05:00","closed_at":"2025-12-19T15:29:28.695776527-05:00","dependencies":[{"issue_id":"Audetic-8jz.16","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:21:54.972130882-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.17","title":"Run bun install and verify dependencies","description":"After all files are in place:\n1. Run 'bun install' from repo root\n2. Verify all catalog dependencies resolve correctly\n3. Check for any peer dependency warnings\n4. Ensure node_modules is properly populated\n\nFiles: bun.lock","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-19T15:22:03.629822388-05:00","updated_at":"2025-12-19T15:29:41.708068462-05:00","closed_at":"2025-12-19T15:29:41.708068462-05:00","dependencies":[{"issue_id":"Audetic-8jz.17","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:22:03.630359024-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.18","title":"Run biome format on new package","description":"Format all new files with Biome:\n1. Run 'bun run fmt' from repo root\n2. Ensure code follows monorepo conventions (tabs, double quotes)\n3. Fix any formatting issues\n\nFiles: packages/inference-server-manager/src/**/*.ts","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-19T15:22:05.86269374-05:00","updated_at":"2025-12-19T15:29:52.712018045-05:00","closed_at":"2025-12-19T15:29:52.712018045-05:00","dependencies":[{"issue_id":"Audetic-8jz.18","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:22:05.863097718-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.19","title":"Run typecheck and fix any errors","description":"Type check the new package:\n1. Run 'bun run typecheck' from repo root\n2. Fix any TypeScript errors\n3. Ensure strict mode passes\n4. Verify path aliases work correctly\n\nFiles: packages/inference-server-manager/src/**/*.ts","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-19T15:22:07.533742839-05:00","updated_at":"2025-12-19T15:30:26.320664836-05:00","closed_at":"2025-12-19T15:30:26.320664836-05:00","dependencies":[{"issue_id":"Audetic-8jz.19","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:22:07.534286118-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.2","title":"Create package directory structure","description":"Create the directory structure for the new package:\npackages/inference-server-manager/\n├── src/\n│   ├── manager/\n│   ├── workers/\n│   ├── routes/\n│   └── observability/\n\nFiles: packages/inference-server-manager/","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-19T15:21:02.460372692-05:00","updated_at":"2025-12-19T15:23:21.633293409-05:00","closed_at":"2025-12-19T15:23:21.633293409-05:00","dependencies":[{"issue_id":"Audetic-8jz.2","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:21:02.461030805-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.20","title":"Test dev server starts successfully","description":"Verify the ported service works:\n1. cd packages/inference-server-manager\n2. Run 'bun run dev'\n3. Verify server starts on configured port\n4. Test /health endpoint returns valid response\n5. Check logs are being written correctly\n\nNote: Full transcription testing requires WhisperServer binary.\n\nFiles: N/A (runtime verification)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-19T15:22:10.420309425-05:00","updated_at":"2025-12-19T15:30:32.137015578-05:00","closed_at":"2025-12-19T15:30:32.137015578-05:00","dependencies":[{"issue_id":"Audetic-8jz.20","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:22:10.420678204-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.3","title":"Create package.json for inference-server-manager","description":"Create package.json with:\n- name: inference-server-manager\n- private: true\n- type: module\n- Scripts: dev, start, test, typecheck\n- Dependencies using catalog: references\n- Strip unused deps from source (sharp, clipboardy, AI SDKs, WorkOS)\n\nFiles: packages/inference-server-manager/package.json","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-19T15:21:04.320280932-05:00","updated_at":"2025-12-19T15:23:38.488648883-05:00","closed_at":"2025-12-19T15:23:38.488648883-05:00","dependencies":[{"issue_id":"Audetic-8jz.3","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:21:04.320813751-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.4","title":"Create tsconfig.json for inference-server-manager","description":"Create tsconfig.json with:\n- target: ES2022\n- module: ESNext\n- moduleResolution: bundler\n- strict: true\n- noUncheckedIndexedAccess: true\n- Path alias: @/* -\u003e ./src/*\n\nFiles: packages/inference-server-manager/tsconfig.json","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-19T15:21:05.903040254-05:00","updated_at":"2025-12-19T15:23:55.391956148-05:00","closed_at":"2025-12-19T15:23:55.391956148-05:00","dependencies":[{"issue_id":"Audetic-8jz.4","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:21:05.903585307-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.5","title":"Port src/global.ts with renamed AppName","description":"Port global.ts from source with modifications:\n- Change AppName from 'transcription-manager' to 'inference-server-manager'\n- Keep XDG config path as 'transcription_manager' for backward compatibility with voice.audetic.link deployment\n- Keep cache versioning logic\n\nFiles: packages/inference-server-manager/src/global.ts","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-19T15:21:15.786996719-05:00","updated_at":"2025-12-19T15:24:18.78634685-05:00","closed_at":"2025-12-19T15:24:18.78634685-05:00","dependencies":[{"issue_id":"Audetic-8jz.5","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:21:15.78761279-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.6","title":"Port src/observability/logger.ts simplified","description":"Port logger.ts with simplifications:\n- Remove identity context loading (lines 31-54)\n- Remove getIdentityContext() function\n- Remove createEnrichedLogger() complexity\n- Change default log level from 'debug' to 'info'\n- Keep pino-pretty and pino-roll transports\n- Keep withTraceContext() for distributed tracing\n\nFiles: packages/inference-server-manager/src/observability/logger.ts","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-19T15:21:18.256374123-05:00","updated_at":"2025-12-19T15:24:42.967749846-05:00","closed_at":"2025-12-19T15:24:42.967749846-05:00","dependencies":[{"issue_id":"Audetic-8jz.6","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:21:18.256913474-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.7","title":"Port src/observability/system.ts as-is","description":"Copy system.ts from source without modifications. Contains system metrics collection (CPU, memory, etc).\n\nFiles: packages/inference-server-manager/src/observability/system.ts","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-19T15:21:19.686794397-05:00","updated_at":"2025-12-19T15:25:30.951266532-05:00","closed_at":"2025-12-19T15:25:30.951266532-05:00","dependencies":[{"issue_id":"Audetic-8jz.7","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:21:19.687439845-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.8","title":"Port src/observability/tracing.ts as-is","description":"Copy tracing.ts from source without modifications. Contains distributed tracing with spans using Bun.randomUUIDv7().\n\nFiles: packages/inference-server-manager/src/observability/tracing.ts","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-19T15:21:21.083073037-05:00","updated_at":"2025-12-19T15:25:30.961966636-05:00","closed_at":"2025-12-19T15:25:30.961966636-05:00","dependencies":[{"issue_id":"Audetic-8jz.8","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:21:21.083650262-05:00","created_by":"daemon"}]}
{"id":"Audetic-8jz.9","title":"Port src/observability/index.ts as-is","description":"Copy observability/index.ts from source without modifications. Contains observability initialization and system metrics pulse logging.\n\nFiles: packages/inference-server-manager/src/observability/index.ts","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-19T15:21:29.395619367-05:00","updated_at":"2025-12-19T15:25:30.971483274-05:00","closed_at":"2025-12-19T15:25:30.971483274-05:00","dependencies":[{"issue_id":"Audetic-8jz.9","depends_on_id":"Audetic-8jz","type":"parent-child","created_at":"2025-12-19T15:21:29.396139301-05:00","created_by":"daemon"}]}
{"id":"Audetic-idj","title":"Voice-triggered workflow system for Audetic","description":"Enable voice-triggered workflows in Audetic, inspired by Arcata's workflow system.\n\n## Core Concept\nUser copies text to clipboard, issues a voice command via Audetic, and the system:\n1. Captures the voice command (transcription)\n2. Reads clipboard content\n3. Routes to appropriate workflow based on voice intent\n4. Executes transformation/extraction/integration\n5. Returns result (clipboard, notification, API call, etc.)\n\n## Example Use Cases\n- \"Summarize this\" → clipboard text gets summarized, result copied back\n- \"Extract action items\" → parses clipboard for todos, sends to task manager\n- \"Translate to Spanish\" → translates clipboard content\n- \"Create a ticket\" → extracts info and creates GitHub/Linear issue\n- \"Send to Notion\" → formats and sends to Notion API\n\n## Architecture (from Arcata)\n- WorkflowV2 base class with step runner and context injection\n- WorkflowRunner singleton for workflow selection/execution\n- Step-based composition (transcribe → collect clipboard → process → output)\n- Event-driven with workflow lifecycle events\n- SQLite for workflow run history\n\n## Key Differences from Arcata\n- Rust-native implementation (not TypeScript/Bun)\n- Focus on CLI-first experience\n- Simpler initial scope (no continuous capture, no screenshots)\n- Plugin/extension system for custom workflows","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-19T09:00:44.361953643-05:00","updated_at":"2025-12-19T09:00:58.85905432-05:00"}
{"id":"Audetic-idj.1","title":"Design workflow trait and base types","description":"Define the core Rust traits and types for the workflow system.\n\n## Deliverables\n- `Workflow` trait with lifecycle methods (init, run, cleanup)\n- `WorkflowContext` struct (config, logger, workflow metadata)\n- `Step` trait for composable workflow steps\n- `WorkflowResult` enum for success/failure with output\n- `WorkflowEvent` enum for lifecycle events (started, progress, ended, failed)\n\n## Design Considerations\n- Async-first with tokio\n- Generic over input/output types\n- Error handling with anyhow/thiserror\n- Tracing integration for observability\n- Consider using enum_dispatch for performance","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-19T09:01:06.298652129-05:00","updated_at":"2025-12-19T09:01:06.298652129-05:00","dependencies":[{"issue_id":"Audetic-idj.1","depends_on_id":"Audetic-idj","type":"parent-child","created_at":"2025-12-19T09:01:06.299361954-05:00","created_by":"daemon"}]}
{"id":"Audetic-idj.2","title":"Implement clipboard integration","description":"Add clipboard read/write support for workflows.\n\n## Deliverables\n- `Clipboard` module in src/text_io/ or new src/clipboard/\n- `read()` - get current clipboard content as String\n- `write(text: \u0026str)` - set clipboard content\n- Platform support: Linux (wl-copy/wl-paste, xclip fallback), macOS (pbcopy/pbpaste)\n\n## Implementation Notes\n- Use std::process::Command for shell tools\n- Handle encoding (UTF-8)\n- Timeout handling for hung clipboard managers\n- Consider arboard crate as alternative to shell commands\n\n## Testing\n- Unit tests with mock clipboard\n- Integration tests on CI (may need xvfb)","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-19T09:01:13.983043071-05:00","updated_at":"2025-12-19T09:01:13.983043071-05:00","dependencies":[{"issue_id":"Audetic-idj.2","depends_on_id":"Audetic-idj","type":"parent-child","created_at":"2025-12-19T09:01:13.983671115-05:00","created_by":"daemon"}]}
{"id":"Audetic-idj.3","title":"Build intent detection from voice commands","description":"Parse transcribed voice commands to determine workflow intent.\n\n## Deliverables\n- `IntentDetector` that maps transcription → WorkflowId\n- Support for keyword matching (\"summarize\", \"translate\", \"extract\")\n- Optional: LLM-based intent classification for complex commands\n- `Intent` struct with workflow_id, parameters, confidence\n\n## Approach Options\n1. **Simple keyword matching** - fast, no dependencies, good for v1\n2. **Regex patterns** - more flexible matching\n3. **LLM classification** - most flexible, requires API call\n\n## Example Mappings\n- \"summarize this\" → Summarize workflow\n- \"translate to spanish\" → Translate workflow with lang=es\n- \"create a ticket for this bug\" → CreateTicket workflow with type=bug\n- \"send to notion\" → NotionSync workflow\n\n## Configuration\nAllow users to define custom intent mappings in config.toml:\n```toml\n[[workflows.intents]]\nkeywords = [\"summarize\", \"sum up\", \"tldr\"]\nworkflow = \"summarize\"\n```","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-19T09:01:26.712385732-05:00","updated_at":"2025-12-19T09:01:26.712385732-05:00","dependencies":[{"issue_id":"Audetic-idj.3","depends_on_id":"Audetic-idj","type":"parent-child","created_at":"2025-12-19T09:01:26.712967375-05:00","created_by":"daemon"},{"issue_id":"Audetic-idj.3","depends_on_id":"Audetic-idj.1","type":"blocks","created_at":"2025-12-19T09:03:02.822330343-05:00","created_by":"daemon"}]}
{"id":"Audetic-idj.4","title":"Implement WorkflowRunner and registry","description":"Central orchestrator for workflow execution.\n\n## Deliverables\n- `WorkflowRunner` struct (singleton pattern like Arcata)\n- `WorkflowRegistry` for registering available workflows\n- `run(intent: Intent)` - execute workflow based on detected intent\n- Event emission for workflow lifecycle\n- Integration with existing recording flow\n\n## Runner Responsibilities\n1. Receive transcription from recording completion\n2. Detect intent from transcription\n3. Gather context (clipboard, config)\n4. Look up workflow in registry\n5. Execute workflow with context\n6. Handle result (clipboard write, notification, etc.)\n\n## Registry Pattern\n```rust\nlet mut registry = WorkflowRegistry::new();\nregistry.register(\"summarize\", SummarizeWorkflow::new());\nregistry.register(\"translate\", TranslateWorkflow::new());\n```\n\n## Integration Point\nHook into existing recording completion in src/audio/recording_machine.rs","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-19T09:01:35.87273867-05:00","updated_at":"2025-12-19T09:01:35.87273867-05:00","dependencies":[{"issue_id":"Audetic-idj.4","depends_on_id":"Audetic-idj","type":"parent-child","created_at":"2025-12-19T09:01:35.873501588-05:00","created_by":"daemon"},{"issue_id":"Audetic-idj.4","depends_on_id":"Audetic-idj.1","type":"blocks","created_at":"2025-12-19T09:03:02.833523998-05:00","created_by":"daemon"},{"issue_id":"Audetic-idj.4","depends_on_id":"Audetic-idj.2","type":"blocks","created_at":"2025-12-19T09:03:02.845352628-05:00","created_by":"daemon"},{"issue_id":"Audetic-idj.4","depends_on_id":"Audetic-idj.3","type":"blocks","created_at":"2025-12-19T09:03:02.856576411-05:00","created_by":"daemon"}]}
{"id":"Audetic-idj.5","title":"Create first workflow: Summarize","description":"Implement the first concrete workflow as a reference implementation.\n\n## Workflow: Summarize\n- **Trigger**: \"summarize this\", \"sum up\", \"tldr\"\n- **Input**: Clipboard text\n- **Process**: Send to LLM with summarization prompt\n- **Output**: Summary copied to clipboard\n\n## Implementation\n```rust\npub struct SummarizeWorkflow;\n\nimpl Workflow for SummarizeWorkflow {\n    async fn run(\u0026self, ctx: WorkflowContext) -\u003e Result\u003cWorkflowResult\u003e {\n        let text = ctx.clipboard.read()?;\n        let summary = ctx.llm.complete(SUMMARIZE_PROMPT, text).await?;\n        ctx.clipboard.write(\u0026summary)?;\n        Ok(WorkflowResult::success(summary))\n    }\n}\n```\n\n## LLM Integration\n- Use existing transcription provider infrastructure if possible\n- Or add new LLM provider abstraction\n- Support OpenAI, Anthropic, local models\n\n## Testing\n- Unit test with mock LLM\n- Integration test with real API (optional, behind feature flag)","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-19T09:01:45.146554309-05:00","updated_at":"2025-12-19T09:01:45.146554309-05:00","dependencies":[{"issue_id":"Audetic-idj.5","depends_on_id":"Audetic-idj","type":"parent-child","created_at":"2025-12-19T09:01:45.147150028-05:00","created_by":"daemon"},{"issue_id":"Audetic-idj.5","depends_on_id":"Audetic-idj.4","type":"blocks","created_at":"2025-12-19T09:03:02.868189017-05:00","created_by":"daemon"},{"issue_id":"Audetic-idj.5","depends_on_id":"Audetic-idj.9","type":"blocks","created_at":"2025-12-19T09:03:02.878088272-05:00","created_by":"daemon"}]}
{"id":"Audetic-idj.6","title":"Add workflow mode toggle to CLI/keybind","description":"Allow users to switch between transcription-only and workflow modes.\n\n## Modes\n1. **Transcription mode** (current default): Voice → text → clipboard\n2. **Workflow mode** (new): Voice → intent detection → workflow execution\n\n## Implementation Options\n1. **Keybind toggle**: Different hotkey for workflow mode\n2. **Config setting**: Default mode in config.toml\n3. **CLI flag**: `audetic record --workflow`\n4. **Prefix detection**: \"Hey Audetic, summarize this\" triggers workflow\n\n## UI Feedback\n- Different notification/sound for workflow mode\n- Show which mode is active in status\n- Waybar integration update\n\n## Config Example\n```toml\n[recording]\ndefault_mode = \"transcription\"  # or \"workflow\"\n\n[keybinds]\nrecord_transcription = \"Super+Shift+Space\"\nrecord_workflow = \"Super+Ctrl+Space\"\n```","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-19T09:01:55.0494391-05:00","updated_at":"2025-12-19T09:01:55.0494391-05:00","dependencies":[{"issue_id":"Audetic-idj.6","depends_on_id":"Audetic-idj","type":"parent-child","created_at":"2025-12-19T09:01:55.050029219-05:00","created_by":"daemon"},{"issue_id":"Audetic-idj.6","depends_on_id":"Audetic-idj.4","type":"blocks","created_at":"2025-12-19T09:03:02.889116311-05:00","created_by":"daemon"}]}
{"id":"Audetic-idj.7","title":"Add workflow run history to database","description":"Track workflow executions in SQLite for debugging and analytics.\n\n## Schema Addition\n```sql\nCREATE TABLE workflow_runs (\n    id INTEGER PRIMARY KEY,\n    workflow_id TEXT NOT NULL,\n    workflow_name TEXT NOT NULL,\n    status TEXT NOT NULL,  -- 'running', 'success', 'failure'\n    input_text TEXT,       -- clipboard content\n    output_text TEXT,      -- result\n    error TEXT,            -- error message if failed\n    started_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n    ended_at DATETIME,\n    duration_ms INTEGER\n);\n```\n\n## Implementation\n- Add schema to src/db/schemas.rs\n- Migration in src/db/init.rs\n- CRUD operations in src/db/operations.rs\n- CLI command: `audetic history workflows`\n\n## Retention\n- Default: keep last 100 runs\n- Configurable in config.toml\n- Auto-cleanup on startup","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-19T09:02:03.092350883-05:00","updated_at":"2025-12-19T09:02:03.092350883-05:00","dependencies":[{"issue_id":"Audetic-idj.7","depends_on_id":"Audetic-idj","type":"parent-child","created_at":"2025-12-19T09:02:03.092910231-05:00","created_by":"daemon"},{"issue_id":"Audetic-idj.7","depends_on_id":"Audetic-idj.1","type":"blocks","created_at":"2025-12-19T09:03:02.899928426-05:00","created_by":"daemon"}]}
{"id":"Audetic-idj.8","title":"Design plugin/extension system for custom workflows","description":"Allow users to add custom workflows without modifying core code.\n\n## Options to Explore\n1. **WASM plugins** - sandboxed, cross-platform, complex\n2. **Lua scripts** - simple, proven (neovim, redis), good FFI\n3. **External commands** - shell scripts, any language, simplest\n4. **Rhai scripts** - Rust-native scripting, good integration\n\n## MVP: External Commands\n```toml\n[[workflows.custom]]\nname = \"my-workflow\"\nkeywords = [\"do the thing\"]\ncommand = \"~/.config/audetic/workflows/my-workflow.sh\"\n# Script receives: stdin=clipboard, env: AUDETIC_TRANSCRIPTION, AUDETIC_INTENT\n# Script outputs: stdout → clipboard\n```\n\n## Future: Lua/WASM\n- Define workflow API surface\n- Sandbox considerations\n- Hot-reload support\n- Error handling and timeouts\n\n## Discovery\n- Scan ~/.config/audetic/workflows/\n- Auto-register based on manifest.toml in each folder","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-19T09:02:14.326682213-05:00","updated_at":"2025-12-19T09:02:14.326682213-05:00","dependencies":[{"issue_id":"Audetic-idj.8","depends_on_id":"Audetic-idj","type":"parent-child","created_at":"2025-12-19T09:02:14.327278464-05:00","created_by":"daemon"},{"issue_id":"Audetic-idj.8","depends_on_id":"Audetic-idj.5","type":"blocks","created_at":"2025-12-19T09:03:02.909108109-05:00","created_by":"daemon"}]}
{"id":"Audetic-idj.9","title":"Add LLM provider abstraction","description":"Abstract LLM calls for workflow processing (separate from transcription).\n\n## Deliverables\n- `LlmProvider` trait with `complete(prompt, input)` method\n- Implementations: OpenAI, Anthropic, Ollama (local)\n- Configuration in config.toml\n- Streaming support (optional for v1)\n\n## Trait Design\n```rust\n#[async_trait]\npub trait LlmProvider: Send + Sync {\n    async fn complete(\u0026self, request: CompletionRequest) -\u003e Result\u003cCompletionResponse\u003e;\n    fn name(\u0026self) -\u003e \u0026str;\n}\n\npub struct CompletionRequest {\n    pub system_prompt: Option\u003cString\u003e,\n    pub user_prompt: String,\n    pub max_tokens: Option\u003cu32\u003e,\n    pub temperature: Option\u003cf32\u003e,\n}\n```\n\n## Config Example\n```toml\n[llm]\nprovider = \"openai\"  # or \"anthropic\", \"ollama\"\nmodel = \"gpt-4o-mini\"\napi_key_env = \"OPENAI_API_KEY\"\n\n[llm.ollama]\nendpoint = \"http://localhost:11434\"\nmodel = \"llama3.2\"\n```\n\n## Reuse Consideration\n- Could potentially share HTTP client with transcription providers\n- Keep separate for now, refactor later if needed","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-19T09:02:29.554050537-05:00","updated_at":"2025-12-19T09:02:29.554050537-05:00","dependencies":[{"issue_id":"Audetic-idj.9","depends_on_id":"Audetic-idj","type":"parent-child","created_at":"2025-12-19T09:02:29.554576609-05:00","created_by":"daemon"}]}
{"id":"Audetic-vuu","title":"Port whisper-server to Audetic monorepo (Vulkan-only)","description":"Port the whisper.cpp server from matsilva/whisper fork to packages/whisper-server/ in the Audetic monorepo.\n\n## Scope\n- Server-only subset of whisper.cpp (not full repo)\n- Vulkan backend only (AMD GPU focus) - strip CUDA, Metal, OpenCL, SYCL, etc.\n- CPU/BLAS fallback for systems without Vulkan\n- User-global model storage at ~/.cache/audetic/models/\n\n## Source\n- Fork: /home/matsilva/code/matsilva/whisper (feat/server-builds branch)\n- Key script: scripts/build_run_whisper_server.sh\n\n## Integration\n- inference-server-manager spawns whisper-server via WHISPER_SERVER_CMD env var\n- Models downloaded once, shared across all Audetic instances\n\n## Non-goals (follow-on tasks)\n- CI/CD pipeline\n- Docker images\n- Pre-built binaries","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-19T16:47:33.564911475-05:00","updated_at":"2025-12-19T16:47:33.564911475-05:00"}
{"id":"Audetic-vuu.1","title":"Create package directory structure","description":"Create the packages/whisper-server/ directory with initial structure:\n\n```\npackages/whisper-server/\n├── README.md\n├── .gitignore\n├── scripts/\n├── src/\n├── ggml/\n├── examples/\n│   └── server/\n└── cmake/\n```\n\nFiles to create:\n- README.md with build instructions, model download, integration with inference-server-manager\n- .gitignore for build artifacts (build/, *.o, *.a, etc.)","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-19T16:47:43.985714236-05:00","updated_at":"2025-12-19T16:47:43.985714236-05:00","dependencies":[{"issue_id":"Audetic-vuu.1","depends_on_id":"Audetic-vuu","type":"parent-child","created_at":"2025-12-19T16:47:43.986337716-05:00","created_by":"daemon"}]}
{"id":"Audetic-vuu.10","title":"Commit whisper-server package","description":"Final commit of the whisper-server package.\n\n## Pre-commit checklist\n- [ ] All files copied and modified\n- [ ] Build tested successfully\n- [ ] README complete\n- [ ] .gitignore in place\n- [ ] No large binary files staged\n\n## Commit message\n```\nfeat: add whisper-server package (Vulkan-only)\n\nPort whisper.cpp server from matsilva/whisper fork with:\n- Vulkan backend for AMD GPU acceleration\n- CPU/BLAS fallback for systems without Vulkan\n- User-global model storage at ~/.cache/audetic/models/\n- Stripped unused backends (CUDA, Metal, OpenCL, etc.)\n\nIntegrates with inference-server-manager via WHISPER_SERVER_CMD env var.\n```\n\n## Files to stage\n- packages/whisper-server/ (entire directory)\n- packages/inference-server-manager/README.md (if updated)","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-19T16:49:26.650136634-05:00","updated_at":"2025-12-19T16:49:26.650136634-05:00","dependencies":[{"issue_id":"Audetic-vuu.10","depends_on_id":"Audetic-vuu","type":"parent-child","created_at":"2025-12-19T16:49:26.65068623-05:00","created_by":"daemon"}]}
{"id":"Audetic-vuu.2","title":"Copy and strip ggml directory (Vulkan-only)","description":"Copy ggml/ from whisper fork, stripping unused backends.\n\n## Keep (essential)\n- ggml/CMakeLists.txt\n- ggml/cmake/ (all)\n- ggml/include/ (all headers)\n- ggml/src/CMakeLists.txt\n- ggml/src/ggml*.c, ggml*.cpp, ggml*.h (core files)\n- ggml/src/gguf.cpp\n- ggml/src/ggml-cpu/ (CPU backend - essential fallback)\n- ggml/src/ggml-blas/ (BLAS acceleration)\n- ggml/src/ggml-vulkan/ (AMD GPU backend)\n\n## Strip (unused backends)\n- ggml/src/ggml-cuda/ (NVIDIA)\n- ggml/src/ggml-metal/ (Apple)\n- ggml/src/ggml-opencl/ (legacy)\n- ggml/src/ggml-sycl/ (Intel)\n- ggml/src/ggml-hip/ (AMD ROCm - different from Vulkan)\n- ggml/src/ggml-musa/ (Moore Threads)\n- ggml/src/ggml-cann/ (Huawei Ascend)\n- ggml/src/ggml-kompute/ (Vulkan compute - redundant)\n- ggml/src/ggml-rpc/ (remote procedure call)\n- ggml/src/ggml-amx/ (Intel AMX)\n\n## Verify\n- CMakeLists.txt still works with stripped backends\n- Vulkan detection logic intact","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-19T16:48:00.591391952-05:00","updated_at":"2025-12-19T16:48:00.591391952-05:00","dependencies":[{"issue_id":"Audetic-vuu.2","depends_on_id":"Audetic-vuu","type":"parent-child","created_at":"2025-12-19T16:48:00.592007126-05:00","created_by":"daemon"}]}
{"id":"Audetic-vuu.3","title":"Copy whisper core source files","description":"Copy essential whisper.cpp source files.\n\n## Root level\n- CMakeLists.txt (main build config)\n- Makefile (convenience wrapper)\n\n## src/\n- src/whisper.cpp\n- src/whisper-arch.h (if exists)\n\n## cmake/\n- cmake/DefaultTargetOptions.cmake\n- cmake/FindFFmpeg.cmake\n- cmake/build-info.cmake\n- cmake/git-vars.cmake\n- cmake/whisper-config.cmake.in\n- cmake/whisper.pc.in\n\n## examples/ (common files)\n- examples/CMakeLists.txt\n- examples/common.cpp\n- examples/common.h\n- examples/common-ggml.cpp\n- examples/common-ggml.h\n- examples/common-whisper.cpp\n- examples/common-whisper.h\n- examples/json.hpp\n- examples/ffmpeg-transcode.cpp (for --convert support)\n\n## examples/server/\n- examples/server/CMakeLists.txt\n- examples/server/server.cpp\n- examples/server/server.slim.cpp\n- examples/server/httplib.h\n- examples/server/README.md","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-19T16:48:11.501584626-05:00","updated_at":"2025-12-19T16:48:11.501584626-05:00","dependencies":[{"issue_id":"Audetic-vuu.3","depends_on_id":"Audetic-vuu","type":"parent-child","created_at":"2025-12-19T16:48:11.502188588-05:00","created_by":"daemon"}]}
{"id":"Audetic-vuu.4","title":"Copy and modify build_run_whisper_server.sh","description":"Copy and adapt the main build/run script for monorepo context.\n\n## Source\nscripts/build_run_whisper_server.sh (313 lines)\n\n## Modifications needed\n\n### Model path changes\n1. Update choose_model() to check ~/.cache/audetic/models/ FIRST\n2. Update download hint message to reference new download script location\n3. Add XDG_CACHE_HOME support: ${XDG_CACHE_HOME:-~/.cache}/audetic/models/\n\n### Path adjustments\n- Script uses relative paths from repo root, should work as-is\n- Verify cmake -B build works from packages/whisper-server/\n\n### Vulkan defaults\n- Keep VULKAN_AUTO=1 (auto-detect)\n- Keep Vulkan detection logic intact\n- Remove any CUDA/Metal references in help text (if any)\n\n### Also copy\n- scripts/run_whisper_server_fast.sh (convenience wrapper)\n- scripts/test_whisper_server.sh (for testing)","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-19T16:48:23.351454476-05:00","updated_at":"2025-12-19T16:48:23.351454476-05:00","dependencies":[{"issue_id":"Audetic-vuu.4","depends_on_id":"Audetic-vuu","type":"parent-child","created_at":"2025-12-19T16:48:23.352031305-05:00","created_by":"daemon"}]}
{"id":"Audetic-vuu.5","title":"Copy and modify download-ggml-model.sh","description":"Copy and adapt the model download script for user-global storage.\n\n## Source\nmodels/download-ggml-model.sh\n\n## Modifications needed\n\n### Default download path\nChange from script directory to XDG cache:\n```bash\n# Old\ndefault_download_path=\"$script_path\"\n\n# New  \ndefault_download_path=\"${XDG_CACHE_HOME:-$HOME/.cache}/audetic/models\"\n```\n\n### Directory creation\nAdd mkdir -p before download:\n```bash\nmkdir -p \"$models_path\"\n```\n\n### Usage update\nUpdate usage message to reflect new default path\n\n### Also copy\n- models/README.md (model documentation)\n- models/.gitignore (ignore downloaded models)\n\n## Location in package\nscripts/download-ggml-model.sh (not models/ - cleaner structure)","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-19T16:48:32.152720557-05:00","updated_at":"2025-12-19T16:48:32.152720557-05:00","dependencies":[{"issue_id":"Audetic-vuu.5","depends_on_id":"Audetic-vuu","type":"parent-child","created_at":"2025-12-19T16:48:32.153281846-05:00","created_by":"daemon"}]}
{"id":"Audetic-vuu.6","title":"Update CMakeLists.txt for stripped backends","description":"Modify root CMakeLists.txt to remove references to stripped backends.\n\n## Changes needed\n\n### Remove deprecated option warnings for stripped backends\nRemove whisper_option_depr() calls for:\n- WHISPER_CUDA / GGML_CUDA\n- WHISPER_METAL / GGML_METAL\n- WHISPER_KOMPUTE / GGML_KOMPUTE\n- WHISPER_SYCL / GGML_SYCL\n- WHISPER_RPC / GGML_RPC\n\n### Keep\n- GGML_VULKAN support\n- GGML_BLAS support\n- GGML_NATIVE support\n- WHISPER_FFMPEG support\n\n### Verify ggml/CMakeLists.txt\n- Ensure it gracefully handles missing backend directories\n- CMake should skip backends that don't exist\n\n### Test\n- cmake -B build -DGGML_VULKAN=ON should work\n- cmake -B build -DGGML_VULKAN=OFF should fall back to CPU/BLAS","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-19T16:48:41.285757756-05:00","updated_at":"2025-12-19T16:48:41.285757756-05:00","dependencies":[{"issue_id":"Audetic-vuu.6","depends_on_id":"Audetic-vuu","type":"parent-child","created_at":"2025-12-19T16:48:41.286440582-05:00","created_by":"daemon"}]}
{"id":"Audetic-vuu.7","title":"Write README.md for whisper-server package","description":"Create comprehensive README for the whisper-server package.\n\n## Sections\n\n### Overview\n- What this is (whisper.cpp server for Audetic)\n- Vulkan-accelerated for AMD GPUs\n- CPU/BLAS fallback\n\n### Prerequisites\n- cmake, ninja (optional)\n- Vulkan SDK (for GPU acceleration)\n- OpenBLAS (for CPU acceleration)\n- ffmpeg (optional, for --convert)\n\n### Quick Start\n```bash\n# Download a model\n./scripts/download-ggml-model.sh large-v3-turbo\n\n# Build and run\n./scripts/build_run_whisper_server.sh\n```\n\n### Model Storage\n- Default: ~/.cache/audetic/models/\n- Override with second arg to download script\n- Recommended models: large-v3-turbo-q5_0 (quality/speed balance)\n\n### Integration with inference-server-manager\n```bash\nexport WHISPER_SERVER_CMD=\"/path/to/packages/whisper-server/scripts/build_run_whisper_server.sh\"\nexport WHISPER_SERVER_CWD=\"/path/to/packages/whisper-server\"\n```\n\n### Build Options\n- --vulkan: Force Vulkan (auto-detected by default)\n- --fast: Low-latency mode\n- --convert: Enable ffmpeg conversion\n- --threads N: Set thread count\n\n### Troubleshooting\n- Vulkan not detected: install vulkan-headers\n- Slow performance: check Vulkan is being used\n- Model not found: run download script first","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-19T16:48:54.980033671-05:00","updated_at":"2025-12-19T16:48:54.980033671-05:00","dependencies":[{"issue_id":"Audetic-vuu.7","depends_on_id":"Audetic-vuu","type":"parent-child","created_at":"2025-12-19T16:48:54.980494693-05:00","created_by":"daemon"}]}
{"id":"Audetic-vuu.8","title":"Test build with Vulkan","description":"Verify the package builds correctly with Vulkan enabled.\n\n## Test steps\n\n### 1. Clean build with Vulkan\n```bash\ncd packages/whisper-server\nrm -rf build\n./scripts/build_run_whisper_server.sh --help  # Should show help\n```\n\n### 2. Build only (don't run)\n```bash\ncmake -B build -DCMAKE_BUILD_TYPE=Release -DGGML_VULKAN=ON -DGGML_BLAS=ON\ncmake --build build --target whisper-server\n```\n\n### 3. Verify binary exists\n```bash\nls -la build/bin/whisper-server\n```\n\n### 4. Test with model (if available)\n```bash\n./scripts/build_run_whisper_server.sh --model ~/.cache/audetic/models/ggml-large-v3-turbo-q5_0.bin\n# In another terminal:\ncurl http://localhost:9009/health\n```\n\n### 5. Verify Vulkan is being used\nCheck build output for \"[detect] Vulkan development files present\"\n\n## Success criteria\n- Build completes without errors\n- whisper-server binary is created\n- Health endpoint responds\n- Vulkan detection works (if Vulkan SDK installed)","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-19T16:49:06.133045084-05:00","updated_at":"2025-12-19T16:49:06.133045084-05:00","dependencies":[{"issue_id":"Audetic-vuu.8","depends_on_id":"Audetic-vuu","type":"parent-child","created_at":"2025-12-19T16:49:06.13357423-05:00","created_by":"daemon"}]}
{"id":"Audetic-vuu.9","title":"Update inference-server-manager integration docs","description":"Update inference-server-manager README to document whisper-server integration.\n\n## Changes to packages/inference-server-manager/README.md\n\n### Add section: Local Whisper Server Setup\n```markdown\n## Local Whisper Server Setup\n\nFor local inference, use the whisper-server package:\n\n1. Download a model:\n   ```bash\n   ./packages/whisper-server/scripts/download-ggml-model.sh large-v3-turbo-q5_0\n   ```\n\n2. Configure environment:\n   ```bash\n   export WHISPER_SERVER_CMD=\"$(pwd)/packages/whisper-server/scripts/build_run_whisper_server.sh\"\n   export WHISPER_SERVER_CWD=\"$(pwd)/packages/whisper-server\"\n   ```\n\n3. Start inference-server-manager:\n   ```bash\n   bun run packages/inference-server-manager/src/index.ts\n   ```\n\nThe manager will automatically start/stop whisper-server instances as needed.\n```\n\n### Update environment variables table\nAdd note that WHISPER_SERVER_CMD should point to whisper-server package","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-19T16:49:16.949648089-05:00","updated_at":"2025-12-19T16:49:16.949648089-05:00","dependencies":[{"issue_id":"Audetic-vuu.9","depends_on_id":"Audetic-vuu","type":"parent-child","created_at":"2025-12-19T16:49:16.950192404-05:00","created_by":"daemon"}]}
